{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gouthammajjari/Intro_to_ml/blob/main/assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMPkqp_ha8jX",
        "outputId": "196c2676-19fd-4f22-e944-d635a77daba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 265 µs (started: 2024-05-04 02:25:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEdC6LDkQ4XS",
        "outputId": "9baca206-3563-4181-9137-b6bc3142d71f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.8 s (started: 2024-05-04 02:25:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlQeX-1R-ia",
        "outputId": "f3ac35a8-cd3d-44de-f231-8d98009154a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a748a42ba90>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.71 ms (started: 2024-05-04 02:26:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsiQp8c3Ux_Q",
        "outputId": "48d0c4c1-fcb8-4a79-d4a7-45d4af9fd123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 42609007.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "time: 16.1 s (started: 2024-05-04 02:26:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Calculate mean and std\n",
        "imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "mean = imgs.view(3, -1).mean(dim=1)\n",
        "std = imgs.view(3, -1).std(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jooydkvUVt8n",
        "outputId": "0e405242-c95a-466f-d99d-85211c2bdd25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 37.4 ms (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC98Saf9VuvN",
        "outputId": "2cc76246-52ee-4196-aac8-2f241f261330"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.16 ms (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJjBdJ1VU-TY",
        "outputId": "d2b6f6d8-deb5-4cc5-a7e0-56c4e963adaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 52.2 ms (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIRtCChAV2nr",
        "outputId": "85b86343-e980-4267-d8ac-343328ed5641"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.38 ms (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItV66gmV1zl",
        "outputId": "a5d7a42c-d5cb-43b3-c60a-832d7ec78a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 645 µs (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Define transformation with calculated mean and std\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7LgQLimUXl2",
        "outputId": "92009f9a-06dd-4f17-bc5b-6edea79040fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 489 ms (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "cifar10 = datasets.CIFAR10(\n",
        "    './data', train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXge3KZ0Ud2I",
        "outputId": "2d663fee-1bb0-4668-a26d-a1996d4b2e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 379 ms (started: 2024-05-04 02:26:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "     './data', train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zGrIQDbdE0r",
        "outputId": "c46f8de3-2359-4173-bab2-1cdf2d9c4078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "time: 7.12 ms (started: 2024-05-04 02:26:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "first_image, label = cifar10[0]\n",
        "print(first_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnSjAIclhyxH",
        "outputId": "5c360503-31a8-4e93-fb8a-635a863138cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 638 µs (started: 2024-05-04 02:26:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(cifar10, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(cifar10_val, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1oMEPlOWeyJ",
        "outputId": "f9d2f76a-5beb-41f4-948e-f8ad582b907a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 155 ms (started: 2024-05-04 02:26:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 10)\n",
        ").to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICZu-ov1cO7y",
        "outputId": "ddb9667f-42fb-40c8-d5d1-8859329e0b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.01 ms (started: 2024-05-04 02:26:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=300, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Testing the model\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predicted = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predicted.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(all_labels, all_predicted)\n",
        "    print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e5OZzeNhGqi",
        "outputId": "182216a5-eb97-4b9c-e5b1-a5d513525da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 1.7894863032104873, Test Accuracy: 41.73%\n",
            "Epoch 2/100, Loss: 1.6517056608840737, Test Accuracy: 42.54%\n",
            "Epoch 3/100, Loss: 1.5802918802219863, Test Accuracy: 44.33%\n",
            "Epoch 4/100, Loss: 1.517758316476606, Test Accuracy: 45.54%\n",
            "Epoch 5/100, Loss: 1.4601751830207181, Test Accuracy: 45.93%\n",
            "Epoch 6/100, Loss: 1.4057868315253743, Test Accuracy: 47.12%\n",
            "Epoch 7/100, Loss: 1.3519397465677805, Test Accuracy: 46.98%\n",
            "Epoch 8/100, Loss: 1.2997348973252265, Test Accuracy: 48.17%\n",
            "Epoch 9/100, Loss: 1.2462299844048683, Test Accuracy: 47.50%\n",
            "Epoch 10/100, Loss: 1.1947670439764695, Test Accuracy: 48.68%\n",
            "Epoch 11/100, Loss: 1.142497247102851, Test Accuracy: 47.90%\n",
            "Epoch 12/100, Loss: 1.0925753005635486, Test Accuracy: 48.14%\n",
            "Epoch 13/100, Loss: 1.0409287122755728, Test Accuracy: 48.22%\n",
            "Epoch 14/100, Loss: 0.9911015565320611, Test Accuracy: 48.42%\n",
            "Epoch 15/100, Loss: 0.9411930450627382, Test Accuracy: 47.76%\n",
            "Epoch 16/100, Loss: 0.89478384010775, Test Accuracy: 48.22%\n",
            "Epoch 17/100, Loss: 0.8451513391576817, Test Accuracy: 46.74%\n",
            "Epoch 18/100, Loss: 0.7985282466149224, Test Accuracy: 47.41%\n",
            "Epoch 19/100, Loss: 0.7524367128704422, Test Accuracy: 47.49%\n",
            "Epoch 20/100, Loss: 0.7085387592924305, Test Accuracy: 46.62%\n",
            "Epoch 21/100, Loss: 0.6645515044377693, Test Accuracy: 46.37%\n",
            "Epoch 22/100, Loss: 0.6256705998363818, Test Accuracy: 47.17%\n",
            "Epoch 23/100, Loss: 0.5873649632862114, Test Accuracy: 46.73%\n",
            "Epoch 24/100, Loss: 0.5499739847309835, Test Accuracy: 46.63%\n",
            "Epoch 25/100, Loss: 0.5154382234399927, Test Accuracy: 45.96%\n",
            "Epoch 26/100, Loss: 0.47981627288340606, Test Accuracy: 46.95%\n",
            "Epoch 27/100, Loss: 0.4475697623047398, Test Accuracy: 46.47%\n",
            "Epoch 28/100, Loss: 0.4166935053835751, Test Accuracy: 47.11%\n",
            "Epoch 29/100, Loss: 0.3876410006561572, Test Accuracy: 45.87%\n",
            "Epoch 30/100, Loss: 0.3599962022105471, Test Accuracy: 46.66%\n",
            "Epoch 31/100, Loss: 0.33406827770893344, Test Accuracy: 46.28%\n",
            "Epoch 32/100, Loss: 0.30920236460001743, Test Accuracy: 46.36%\n",
            "Epoch 33/100, Loss: 0.2871049947545686, Test Accuracy: 45.26%\n",
            "Epoch 34/100, Loss: 0.26559364053010176, Test Accuracy: 46.05%\n",
            "Epoch 35/100, Loss: 0.2446956882492823, Test Accuracy: 45.49%\n",
            "Epoch 36/100, Loss: 0.22736432111595048, Test Accuracy: 46.19%\n",
            "Epoch 37/100, Loss: 0.21064874813465911, Test Accuracy: 46.23%\n",
            "Epoch 38/100, Loss: 0.1956925082472716, Test Accuracy: 46.14%\n",
            "Epoch 39/100, Loss: 0.18009010811770718, Test Accuracy: 45.79%\n",
            "Epoch 40/100, Loss: 0.16647916071960656, Test Accuracy: 44.23%\n",
            "Epoch 41/100, Loss: 0.15309267042780333, Test Accuracy: 45.90%\n",
            "Epoch 42/100, Loss: 0.14147976420519448, Test Accuracy: 45.66%\n",
            "Epoch 43/100, Loss: 0.1292884512777635, Test Accuracy: 46.29%\n",
            "Epoch 44/100, Loss: 0.11972534805965286, Test Accuracy: 45.60%\n",
            "Epoch 45/100, Loss: 0.1123073948803462, Test Accuracy: 45.95%\n",
            "Epoch 46/100, Loss: 0.10401757846342702, Test Accuracy: 46.04%\n",
            "Epoch 47/100, Loss: 0.09636776943787008, Test Accuracy: 46.13%\n",
            "Epoch 48/100, Loss: 0.0883364717446873, Test Accuracy: 45.65%\n",
            "Epoch 49/100, Loss: 0.08331144373847252, Test Accuracy: 45.60%\n",
            "Epoch 50/100, Loss: 0.07853223754525643, Test Accuracy: 46.13%\n",
            "Epoch 51/100, Loss: 0.07216325184295784, Test Accuracy: 46.23%\n",
            "Epoch 52/100, Loss: 0.06739084424495087, Test Accuracy: 45.18%\n",
            "Epoch 53/100, Loss: 0.0645022848078782, Test Accuracy: 46.31%\n",
            "Epoch 54/100, Loss: 0.05906638407618551, Test Accuracy: 45.81%\n",
            "Epoch 55/100, Loss: 0.05586463818594727, Test Accuracy: 45.96%\n",
            "Epoch 56/100, Loss: 0.05264009275162022, Test Accuracy: 46.03%\n",
            "Epoch 57/100, Loss: 0.04861837751229108, Test Accuracy: 46.15%\n",
            "Epoch 58/100, Loss: 0.04628114620854057, Test Accuracy: 46.12%\n",
            "Epoch 59/100, Loss: 0.043458666281818735, Test Accuracy: 45.89%\n",
            "Epoch 60/100, Loss: 0.042025703930260845, Test Accuracy: 46.07%\n",
            "Epoch 61/100, Loss: 0.03969708239088837, Test Accuracy: 46.43%\n",
            "Epoch 62/100, Loss: 0.038123581719347016, Test Accuracy: 45.40%\n",
            "Epoch 63/100, Loss: 0.036226467421291465, Test Accuracy: 46.48%\n",
            "Epoch 64/100, Loss: 0.0344354390343669, Test Accuracy: 46.01%\n",
            "Epoch 65/100, Loss: 0.033310408509137995, Test Accuracy: 46.33%\n",
            "Epoch 66/100, Loss: 0.03197330618438073, Test Accuracy: 46.53%\n",
            "Epoch 67/100, Loss: 0.030803480261837872, Test Accuracy: 46.31%\n",
            "Epoch 68/100, Loss: 0.029140961445839414, Test Accuracy: 46.24%\n",
            "Epoch 69/100, Loss: 0.02800677445736819, Test Accuracy: 46.52%\n",
            "Epoch 70/100, Loss: 0.027254540330217347, Test Accuracy: 45.58%\n",
            "Epoch 71/100, Loss: 0.026435863408388157, Test Accuracy: 46.65%\n",
            "Epoch 72/100, Loss: 0.025370608691080824, Test Accuracy: 46.60%\n",
            "Epoch 73/100, Loss: 0.02420538850664921, Test Accuracy: 46.30%\n",
            "Epoch 74/100, Loss: 0.023740276435696386, Test Accuracy: 46.29%\n",
            "Epoch 75/100, Loss: 0.02260256792768426, Test Accuracy: 46.45%\n",
            "Epoch 76/100, Loss: 0.02191998251140003, Test Accuracy: 46.30%\n",
            "Epoch 77/100, Loss: 0.021694036322197165, Test Accuracy: 46.39%\n",
            "Epoch 78/100, Loss: 0.020688621267099565, Test Accuracy: 46.39%\n",
            "Epoch 79/100, Loss: 0.02038243867192353, Test Accuracy: 46.57%\n",
            "Epoch 80/100, Loss: 0.01960391480289757, Test Accuracy: 46.16%\n",
            "Epoch 81/100, Loss: 0.018977699485522238, Test Accuracy: 46.44%\n",
            "Epoch 82/100, Loss: 0.018327077066255297, Test Accuracy: 46.51%\n",
            "Epoch 83/100, Loss: 0.018001160526592154, Test Accuracy: 46.52%\n",
            "Epoch 84/100, Loss: 0.017547935997007828, Test Accuracy: 46.40%\n",
            "Epoch 85/100, Loss: 0.017613644902942965, Test Accuracy: 46.43%\n",
            "Epoch 86/100, Loss: 0.016801069787645655, Test Accuracy: 46.27%\n",
            "Epoch 87/100, Loss: 0.01701894650111834, Test Accuracy: 46.45%\n",
            "Epoch 88/100, Loss: 0.01618590828487727, Test Accuracy: 46.42%\n",
            "Epoch 89/100, Loss: 0.015575339353893021, Test Accuracy: 46.46%\n",
            "Epoch 90/100, Loss: 0.015323273309042304, Test Accuracy: 45.90%\n",
            "Epoch 91/100, Loss: 0.014816178045857052, Test Accuracy: 46.37%\n",
            "Epoch 92/100, Loss: 0.014521788047794646, Test Accuracy: 46.34%\n",
            "Epoch 93/100, Loss: 0.014249935071982123, Test Accuracy: 46.55%\n",
            "Epoch 94/100, Loss: 0.014018274236813674, Test Accuracy: 46.56%\n",
            "Epoch 95/100, Loss: 0.013714118269870984, Test Accuracy: 46.55%\n",
            "Epoch 96/100, Loss: 0.013484254618838514, Test Accuracy: 46.54%\n",
            "Epoch 97/100, Loss: 0.013293567841714076, Test Accuracy: 46.22%\n",
            "Epoch 98/100, Loss: 0.01290272863704523, Test Accuracy: 46.33%\n",
            "Epoch 99/100, Loss: 0.012622299130114601, Test Accuracy: 46.57%\n",
            "Epoch 100/100, Loss: 0.012379389972457577, Test Accuracy: 46.59%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.55      0.54      1000\n",
            "           1       0.61      0.55      0.58      1000\n",
            "           2       0.35      0.35      0.35      1000\n",
            "           3       0.30      0.29      0.29      1000\n",
            "           4       0.40      0.43      0.41      1000\n",
            "           5       0.34      0.34      0.34      1000\n",
            "           6       0.49      0.53      0.51      1000\n",
            "           7       0.54      0.47      0.50      1000\n",
            "           8       0.57      0.62      0.60      1000\n",
            "           9       0.53      0.53      0.53      1000\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.47      0.47      0.47     10000\n",
            "weighted avg       0.47      0.47      0.47     10000\n",
            "\n",
            "time: 15min 20s (started: 2024-05-04 03:14:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_model(model, train_loader, test_loader, num_epochs=100, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwT6edYguxUz",
        "outputId": "23cefe3d-bca3-49d1-cb6e-a01a05afc322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17.4 ms (started: 2024-05-04 02:26:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tf4CmrcvQvg",
        "outputId": "84dd9b64-c28e-4dd5-a7ce-aceefd368f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 1.8558505601175153, Test Accuracy: 39.45%\n",
            "Epoch 2/300, Loss: 1.690991407011231, Test Accuracy: 42.14%\n",
            "Epoch 3/300, Loss: 1.6219095023717167, Test Accuracy: 43.75%\n",
            "Epoch 4/300, Loss: 1.5618384869069681, Test Accuracy: 44.91%\n",
            "Epoch 5/300, Loss: 1.5054588581001003, Test Accuracy: 46.76%\n",
            "Epoch 6/300, Loss: 1.4501071113542494, Test Accuracy: 47.13%\n",
            "Epoch 7/300, Loss: 1.393197675279067, Test Accuracy: 47.28%\n",
            "Epoch 8/300, Loss: 1.3340140860277494, Test Accuracy: 48.18%\n",
            "Epoch 9/300, Loss: 1.2791666343893977, Test Accuracy: 48.68%\n",
            "Epoch 10/300, Loss: 1.2184916274408766, Test Accuracy: 45.78%\n",
            "Epoch 11/300, Loss: 1.1621051681628993, Test Accuracy: 49.30%\n",
            "Epoch 12/300, Loss: 1.1008202402696958, Test Accuracy: 47.51%\n",
            "Epoch 13/300, Loss: 1.0398080933193175, Test Accuracy: 49.00%\n",
            "Epoch 14/300, Loss: 0.9811650291895607, Test Accuracy: 47.63%\n",
            "Epoch 15/300, Loss: 0.916386367625635, Test Accuracy: 47.34%\n",
            "Epoch 16/300, Loss: 0.8549687948008797, Test Accuracy: 45.03%\n",
            "Epoch 17/300, Loss: 0.8012499065446457, Test Accuracy: 44.71%\n",
            "Epoch 18/300, Loss: 0.7450869032113276, Test Accuracy: 45.10%\n",
            "Epoch 19/300, Loss: 0.6864513892892531, Test Accuracy: 47.05%\n",
            "Epoch 20/300, Loss: 0.6348032049086333, Test Accuracy: 46.47%\n",
            "Epoch 21/300, Loss: 0.5887403315504011, Test Accuracy: 46.07%\n",
            "Epoch 22/300, Loss: 0.5405876192044388, Test Accuracy: 47.25%\n",
            "Epoch 23/300, Loss: 0.49197202398467355, Test Accuracy: 44.90%\n",
            "Epoch 24/300, Loss: 0.45213241895192413, Test Accuracy: 46.31%\n",
            "Epoch 25/300, Loss: 0.41184073196567944, Test Accuracy: 41.17%\n",
            "Epoch 26/300, Loss: 0.36984835889235723, Test Accuracy: 45.38%\n",
            "Epoch 27/300, Loss: 0.33810822908323845, Test Accuracy: 45.77%\n",
            "Epoch 28/300, Loss: 0.3053891835585284, Test Accuracy: 42.86%\n",
            "Epoch 29/300, Loss: 0.2747397420979126, Test Accuracy: 44.36%\n",
            "Epoch 30/300, Loss: 0.24928551772400803, Test Accuracy: 45.65%\n",
            "Epoch 31/300, Loss: 0.2219775808630696, Test Accuracy: 44.57%\n",
            "Epoch 32/300, Loss: 0.20216022566275496, Test Accuracy: 44.64%\n",
            "Epoch 33/300, Loss: 0.17810683576145847, Test Accuracy: 45.36%\n",
            "Epoch 34/300, Loss: 0.1614790043077996, Test Accuracy: 46.11%\n",
            "Epoch 35/300, Loss: 0.14539334375199148, Test Accuracy: 45.35%\n",
            "Epoch 36/300, Loss: 0.12729368473314373, Test Accuracy: 43.19%\n",
            "Epoch 37/300, Loss: 0.12216929374149478, Test Accuracy: 45.97%\n",
            "Epoch 38/300, Loss: 0.10775159193192128, Test Accuracy: 44.83%\n",
            "Epoch 39/300, Loss: 0.10410361975951028, Test Accuracy: 45.64%\n",
            "Epoch 40/300, Loss: 0.08338046429699057, Test Accuracy: 46.02%\n",
            "Epoch 41/300, Loss: 0.07157529354177687, Test Accuracy: 46.20%\n",
            "Epoch 42/300, Loss: 0.07012602182907206, Test Accuracy: 45.23%\n",
            "Epoch 43/300, Loss: 0.04886214479313054, Test Accuracy: 46.05%\n",
            "Epoch 44/300, Loss: 0.050869459252070426, Test Accuracy: 46.02%\n",
            "Epoch 45/300, Loss: 0.04407173973315718, Test Accuracy: 46.71%\n",
            "Epoch 46/300, Loss: 0.030472224613714793, Test Accuracy: 46.64%\n",
            "Epoch 47/300, Loss: 0.01916289786624669, Test Accuracy: 46.79%\n",
            "Epoch 48/300, Loss: 0.011704799639384643, Test Accuracy: 46.60%\n",
            "Epoch 49/300, Loss: 0.012540247082925966, Test Accuracy: 46.14%\n",
            "Epoch 50/300, Loss: 0.01458601330666757, Test Accuracy: 46.42%\n",
            "Epoch 51/300, Loss: 0.006948648220832654, Test Accuracy: 46.91%\n",
            "Epoch 52/300, Loss: 0.00605368452846482, Test Accuracy: 46.87%\n",
            "Epoch 53/300, Loss: 0.004088511958818702, Test Accuracy: 46.89%\n",
            "Epoch 54/300, Loss: 0.0029002068681902803, Test Accuracy: 47.01%\n",
            "Epoch 55/300, Loss: 0.0025531909777782857, Test Accuracy: 46.78%\n",
            "Epoch 56/300, Loss: 0.0022978570020441218, Test Accuracy: 47.08%\n",
            "Epoch 57/300, Loss: 0.0020965933647055612, Test Accuracy: 46.80%\n",
            "Epoch 58/300, Loss: 0.001972080934746578, Test Accuracy: 47.18%\n",
            "Epoch 59/300, Loss: 0.0018453252919182724, Test Accuracy: 46.96%\n",
            "Epoch 60/300, Loss: 0.0017869589486722765, Test Accuracy: 46.89%\n",
            "Epoch 61/300, Loss: 0.001697313422103301, Test Accuracy: 46.95%\n",
            "Epoch 62/300, Loss: 0.0016048094195147509, Test Accuracy: 46.97%\n",
            "Epoch 63/300, Loss: 0.0015454948877357722, Test Accuracy: 46.97%\n",
            "Epoch 64/300, Loss: 0.0014882028117473222, Test Accuracy: 46.94%\n",
            "Epoch 65/300, Loss: 0.0014515379651755592, Test Accuracy: 46.93%\n",
            "Epoch 66/300, Loss: 0.0013775476180227033, Test Accuracy: 46.99%\n",
            "Epoch 67/300, Loss: 0.0013249648251315734, Test Accuracy: 46.95%\n",
            "Epoch 68/300, Loss: 0.0012859924288708788, Test Accuracy: 46.76%\n",
            "Epoch 69/300, Loss: 0.001241998947478005, Test Accuracy: 46.86%\n",
            "Epoch 70/300, Loss: 0.0012127522508982003, Test Accuracy: 46.98%\n",
            "Epoch 71/300, Loss: 0.0011713117879202561, Test Accuracy: 46.80%\n",
            "Epoch 72/300, Loss: 0.0011401241908696918, Test Accuracy: 46.97%\n",
            "Epoch 73/300, Loss: 0.0011088817711776243, Test Accuracy: 46.82%\n",
            "Epoch 74/300, Loss: 0.0010796389478651756, Test Accuracy: 46.83%\n",
            "Epoch 75/300, Loss: 0.0010501893474607206, Test Accuracy: 46.93%\n",
            "Epoch 76/300, Loss: 0.0010246098290788341, Test Accuracy: 46.82%\n",
            "Epoch 77/300, Loss: 0.000996142530509033, Test Accuracy: 46.78%\n",
            "Epoch 78/300, Loss: 0.0009761701380224423, Test Accuracy: 46.91%\n",
            "Epoch 79/300, Loss: 0.0009555065671572794, Test Accuracy: 46.80%\n",
            "Epoch 80/300, Loss: 0.0009291084812178264, Test Accuracy: 46.79%\n",
            "Epoch 81/300, Loss: 0.0009115840628566203, Test Accuracy: 46.84%\n",
            "Epoch 82/300, Loss: 0.0008906549097441604, Test Accuracy: 46.91%\n",
            "Epoch 83/300, Loss: 0.0008712809340940742, Test Accuracy: 46.81%\n",
            "Epoch 84/300, Loss: 0.0008546577345472459, Test Accuracy: 46.82%\n",
            "Epoch 85/300, Loss: 0.0008385278110839134, Test Accuracy: 46.78%\n",
            "Epoch 86/300, Loss: 0.0008208892094579889, Test Accuracy: 46.85%\n",
            "Epoch 87/300, Loss: 0.0008046250514290161, Test Accuracy: 46.73%\n",
            "Epoch 88/300, Loss: 0.0007893230075759054, Test Accuracy: 46.73%\n",
            "Epoch 89/300, Loss: 0.0007747265190863744, Test Accuracy: 46.67%\n",
            "Epoch 90/300, Loss: 0.0007599911225574736, Test Accuracy: 46.77%\n",
            "Epoch 91/300, Loss: 0.0007458965009858508, Test Accuracy: 46.81%\n",
            "Epoch 92/300, Loss: 0.0007348254082466148, Test Accuracy: 46.80%\n",
            "Epoch 93/300, Loss: 0.0007226407778909208, Test Accuracy: 46.70%\n",
            "Epoch 94/300, Loss: 0.0007089838420104364, Test Accuracy: 46.79%\n",
            "Epoch 95/300, Loss: 0.0006963448343116711, Test Accuracy: 46.76%\n",
            "Epoch 96/300, Loss: 0.0006850340127716585, Test Accuracy: 46.82%\n",
            "Epoch 97/300, Loss: 0.0006747231118698168, Test Accuracy: 46.71%\n",
            "Epoch 98/300, Loss: 0.0006637435644192911, Test Accuracy: 46.71%\n",
            "Epoch 99/300, Loss: 0.0006537069578744294, Test Accuracy: 46.82%\n",
            "Epoch 100/300, Loss: 0.0006437954235420058, Test Accuracy: 46.77%\n",
            "Epoch 101/300, Loss: 0.000634445808865118, Test Accuracy: 46.73%\n",
            "Epoch 102/300, Loss: 0.000625062523858776, Test Accuracy: 46.73%\n",
            "Epoch 103/300, Loss: 0.0006160105304265638, Test Accuracy: 46.81%\n",
            "Epoch 104/300, Loss: 0.0006059831104694757, Test Accuracy: 46.80%\n",
            "Epoch 105/300, Loss: 0.0005976902597402243, Test Accuracy: 46.73%\n",
            "Epoch 106/300, Loss: 0.0005894042854659112, Test Accuracy: 46.78%\n",
            "Epoch 107/300, Loss: 0.0005807048735160098, Test Accuracy: 46.72%\n",
            "Epoch 108/300, Loss: 0.0005730342943088306, Test Accuracy: 46.72%\n",
            "Epoch 109/300, Loss: 0.0005656708507664991, Test Accuracy: 46.78%\n",
            "Epoch 110/300, Loss: 0.0005583079402730189, Test Accuracy: 46.70%\n",
            "Epoch 111/300, Loss: 0.0005504470608290702, Test Accuracy: 46.73%\n",
            "Epoch 112/300, Loss: 0.0005440358761663746, Test Accuracy: 46.76%\n",
            "Epoch 113/300, Loss: 0.0005362069808824526, Test Accuracy: 46.74%\n",
            "Epoch 114/300, Loss: 0.000529914043053269, Test Accuracy: 46.70%\n",
            "Epoch 115/300, Loss: 0.0005230387327166975, Test Accuracy: 46.74%\n",
            "Epoch 116/300, Loss: 0.0005165383439012478, Test Accuracy: 46.70%\n",
            "Epoch 117/300, Loss: 0.000510499853934924, Test Accuracy: 46.70%\n",
            "Epoch 118/300, Loss: 0.0005037018644783744, Test Accuracy: 46.80%\n",
            "Epoch 119/300, Loss: 0.000497861791337898, Test Accuracy: 46.74%\n",
            "Epoch 120/300, Loss: 0.0004923672419729162, Test Accuracy: 46.79%\n",
            "Epoch 121/300, Loss: 0.00048655712681283826, Test Accuracy: 46.70%\n",
            "Epoch 122/300, Loss: 0.00048130647625216425, Test Accuracy: 46.76%\n",
            "Epoch 123/300, Loss: 0.0004755042460422322, Test Accuracy: 46.74%\n",
            "Epoch 124/300, Loss: 0.0004700625726672501, Test Accuracy: 46.66%\n",
            "Epoch 125/300, Loss: 0.0004650728813696102, Test Accuracy: 46.78%\n",
            "Epoch 126/300, Loss: 0.00046020689432058477, Test Accuracy: 46.77%\n",
            "Epoch 127/300, Loss: 0.00045467743916575266, Test Accuracy: 46.74%\n",
            "Epoch 128/300, Loss: 0.000449779268829149, Test Accuracy: 46.72%\n",
            "Epoch 129/300, Loss: 0.000445036141421799, Test Accuracy: 46.64%\n",
            "Epoch 130/300, Loss: 0.00044036469146064395, Test Accuracy: 46.73%\n",
            "Epoch 131/300, Loss: 0.00043602470300423715, Test Accuracy: 46.78%\n",
            "Epoch 132/300, Loss: 0.00043120684681051505, Test Accuracy: 46.80%\n",
            "Epoch 133/300, Loss: 0.00042679470766808535, Test Accuracy: 46.74%\n",
            "Epoch 134/300, Loss: 0.0004223155901982641, Test Accuracy: 46.78%\n",
            "Epoch 135/300, Loss: 0.0004184291705970908, Test Accuracy: 46.75%\n",
            "Epoch 136/300, Loss: 0.00041412497481530246, Test Accuracy: 46.75%\n",
            "Epoch 137/300, Loss: 0.000410069012455821, Test Accuracy: 46.71%\n",
            "Epoch 138/300, Loss: 0.00040595940595514467, Test Accuracy: 46.68%\n",
            "Epoch 139/300, Loss: 0.0004020549140809347, Test Accuracy: 46.68%\n",
            "Epoch 140/300, Loss: 0.00039802674879364655, Test Accuracy: 46.75%\n",
            "Epoch 141/300, Loss: 0.00039438822303750564, Test Accuracy: 46.79%\n",
            "Epoch 142/300, Loss: 0.00039091366633493694, Test Accuracy: 46.78%\n",
            "Epoch 143/300, Loss: 0.00038721212210870743, Test Accuracy: 46.71%\n",
            "Epoch 144/300, Loss: 0.00038344037982979156, Test Accuracy: 46.74%\n",
            "Epoch 145/300, Loss: 0.00038030009347746885, Test Accuracy: 46.74%\n",
            "Epoch 146/300, Loss: 0.0003764465943910852, Test Accuracy: 46.74%\n",
            "Epoch 147/300, Loss: 0.00037326484813798226, Test Accuracy: 46.73%\n",
            "Epoch 148/300, Loss: 0.0003702422709338175, Test Accuracy: 46.69%\n",
            "Epoch 149/300, Loss: 0.00036682265776164695, Test Accuracy: 46.75%\n",
            "Epoch 150/300, Loss: 0.00036376763493508924, Test Accuracy: 46.79%\n",
            "Epoch 151/300, Loss: 0.00036045899377466653, Test Accuracy: 46.74%\n",
            "Epoch 152/300, Loss: 0.0003570391264001816, Test Accuracy: 46.73%\n",
            "Epoch 153/300, Loss: 0.00035426898103672715, Test Accuracy: 46.77%\n",
            "Epoch 154/300, Loss: 0.00035117829802966844, Test Accuracy: 46.73%\n",
            "Epoch 155/300, Loss: 0.000348328278581442, Test Accuracy: 46.73%\n",
            "Epoch 156/300, Loss: 0.00034516612401497873, Test Accuracy: 46.74%\n",
            "Epoch 157/300, Loss: 0.00034227319050788663, Test Accuracy: 46.72%\n",
            "Epoch 158/300, Loss: 0.00033936320179304725, Test Accuracy: 46.72%\n",
            "Epoch 159/300, Loss: 0.00033678409380047126, Test Accuracy: 46.70%\n",
            "Epoch 160/300, Loss: 0.00033402985938754253, Test Accuracy: 46.69%\n",
            "Epoch 161/300, Loss: 0.00033122839671977474, Test Accuracy: 46.71%\n",
            "Epoch 162/300, Loss: 0.00032890604341775654, Test Accuracy: 46.73%\n",
            "Epoch 163/300, Loss: 0.0003262531803276596, Test Accuracy: 46.78%\n",
            "Epoch 164/300, Loss: 0.0003235175298742583, Test Accuracy: 46.73%\n",
            "Epoch 165/300, Loss: 0.00032094582251746207, Test Accuracy: 46.73%\n",
            "Epoch 166/300, Loss: 0.00031851337442908353, Test Accuracy: 46.75%\n",
            "Epoch 167/300, Loss: 0.00031590465660346554, Test Accuracy: 46.72%\n",
            "Epoch 168/300, Loss: 0.00031361207825636553, Test Accuracy: 46.70%\n",
            "Epoch 169/300, Loss: 0.00031131713567458786, Test Accuracy: 46.73%\n",
            "Epoch 170/300, Loss: 0.0003090770933072867, Test Accuracy: 46.67%\n",
            "Epoch 171/300, Loss: 0.00030668407144065634, Test Accuracy: 46.74%\n",
            "Epoch 172/300, Loss: 0.0003042551895397744, Test Accuracy: 46.76%\n",
            "Epoch 173/300, Loss: 0.00030229745691615203, Test Accuracy: 46.69%\n",
            "Epoch 174/300, Loss: 0.00029983953506241434, Test Accuracy: 46.68%\n",
            "Epoch 175/300, Loss: 0.00029765949291364044, Test Accuracy: 46.79%\n",
            "Epoch 176/300, Loss: 0.0002953433832863491, Test Accuracy: 46.75%\n",
            "Epoch 177/300, Loss: 0.0002935318094708388, Test Accuracy: 46.71%\n",
            "Epoch 178/300, Loss: 0.0002913748826390646, Test Accuracy: 46.67%\n",
            "Epoch 179/300, Loss: 0.00028937338172284273, Test Accuracy: 46.69%\n",
            "Epoch 180/300, Loss: 0.00028715100957023965, Test Accuracy: 46.71%\n",
            "Epoch 181/300, Loss: 0.0002853940362444413, Test Accuracy: 46.71%\n",
            "Epoch 182/300, Loss: 0.0002833120942075414, Test Accuracy: 46.71%\n",
            "Epoch 183/300, Loss: 0.00028160515880603666, Test Accuracy: 46.71%\n",
            "Epoch 184/300, Loss: 0.00027919585534331363, Test Accuracy: 46.71%\n",
            "Epoch 185/300, Loss: 0.00027748654675532924, Test Accuracy: 46.74%\n",
            "Epoch 186/300, Loss: 0.0002757251047998442, Test Accuracy: 46.67%\n",
            "Epoch 187/300, Loss: 0.0002739236824907066, Test Accuracy: 46.67%\n",
            "Epoch 188/300, Loss: 0.0002719440844227421, Test Accuracy: 46.70%\n",
            "Epoch 189/300, Loss: 0.00027031808282153785, Test Accuracy: 46.72%\n",
            "Epoch 190/300, Loss: 0.00026856406477744876, Test Accuracy: 46.72%\n",
            "Epoch 191/300, Loss: 0.00026655811861422426, Test Accuracy: 46.67%\n",
            "Epoch 192/300, Loss: 0.00026498171293336254, Test Accuracy: 46.68%\n",
            "Epoch 193/300, Loss: 0.0002633165182343265, Test Accuracy: 46.68%\n",
            "Epoch 194/300, Loss: 0.0002615157281421304, Test Accuracy: 46.70%\n",
            "Epoch 195/300, Loss: 0.00025984265552683966, Test Accuracy: 46.77%\n",
            "Epoch 196/300, Loss: 0.00025834112813628786, Test Accuracy: 46.69%\n",
            "Epoch 197/300, Loss: 0.00025648916281733073, Test Accuracy: 46.74%\n",
            "Epoch 198/300, Loss: 0.00025502995713517845, Test Accuracy: 46.69%\n",
            "Epoch 199/300, Loss: 0.0002535609557377222, Test Accuracy: 46.72%\n",
            "Epoch 200/300, Loss: 0.00025181565762392316, Test Accuracy: 46.69%\n",
            "Epoch 201/300, Loss: 0.0002502717638125131, Test Accuracy: 46.65%\n",
            "Epoch 202/300, Loss: 0.00024862089672159245, Test Accuracy: 46.72%\n",
            "Epoch 203/300, Loss: 0.0002472751089181067, Test Accuracy: 46.69%\n",
            "Epoch 204/300, Loss: 0.00024571807935909305, Test Accuracy: 46.69%\n",
            "Epoch 205/300, Loss: 0.00024426996607216636, Test Accuracy: 46.72%\n",
            "Epoch 206/300, Loss: 0.0002428806329983801, Test Accuracy: 46.73%\n",
            "Epoch 207/300, Loss: 0.00024141028472015328, Test Accuracy: 46.73%\n",
            "Epoch 208/300, Loss: 0.00023992031809074092, Test Accuracy: 46.70%\n",
            "Epoch 209/300, Loss: 0.000238463028396795, Test Accuracy: 46.72%\n",
            "Epoch 210/300, Loss: 0.00023723926802929395, Test Accuracy: 46.70%\n",
            "Epoch 211/300, Loss: 0.00023581414242519806, Test Accuracy: 46.71%\n",
            "Epoch 212/300, Loss: 0.00023438945227063972, Test Accuracy: 46.71%\n",
            "Epoch 213/300, Loss: 0.00023309494544434948, Test Accuracy: 46.66%\n",
            "Epoch 214/300, Loss: 0.00023170215098385598, Test Accuracy: 46.70%\n",
            "Epoch 215/300, Loss: 0.0002303696263293865, Test Accuracy: 46.68%\n",
            "Epoch 216/300, Loss: 0.00022916806907490164, Test Accuracy: 46.69%\n",
            "Epoch 217/300, Loss: 0.00022771734523443403, Test Accuracy: 46.67%\n",
            "Epoch 218/300, Loss: 0.0002263908941471782, Test Accuracy: 46.71%\n",
            "Epoch 219/300, Loss: 0.0002252692454975317, Test Accuracy: 46.69%\n",
            "Epoch 220/300, Loss: 0.00022391361825316948, Test Accuracy: 46.69%\n",
            "Epoch 221/300, Loss: 0.00022280492170884255, Test Accuracy: 46.73%\n",
            "Epoch 222/300, Loss: 0.00022142636096728394, Test Accuracy: 46.73%\n",
            "Epoch 223/300, Loss: 0.000220371603931721, Test Accuracy: 46.68%\n",
            "Epoch 224/300, Loss: 0.00021917437187326573, Test Accuracy: 46.66%\n",
            "Epoch 225/300, Loss: 0.00021800574189280943, Test Accuracy: 46.66%\n",
            "Epoch 226/300, Loss: 0.00021674171426244555, Test Accuracy: 46.65%\n",
            "Epoch 227/300, Loss: 0.00021558559203950327, Test Accuracy: 46.67%\n",
            "Epoch 228/300, Loss: 0.00021451620468247135, Test Accuracy: 46.62%\n",
            "Epoch 229/300, Loss: 0.00021331634736261333, Test Accuracy: 46.69%\n",
            "Epoch 230/300, Loss: 0.00021219996017298435, Test Accuracy: 46.61%\n",
            "Epoch 231/300, Loss: 0.00021105322253417227, Test Accuracy: 46.67%\n",
            "Epoch 232/300, Loss: 0.00020991476762578635, Test Accuracy: 46.67%\n",
            "Epoch 233/300, Loss: 0.00020891800617303262, Test Accuracy: 46.68%\n",
            "Epoch 234/300, Loss: 0.00020778384732425998, Test Accuracy: 46.66%\n",
            "Epoch 235/300, Loss: 0.00020672242373792052, Test Accuracy: 46.65%\n",
            "Epoch 236/300, Loss: 0.00020572410570971503, Test Accuracy: 46.65%\n",
            "Epoch 237/300, Loss: 0.00020468009157669067, Test Accuracy: 46.60%\n",
            "Epoch 238/300, Loss: 0.00020359742034603385, Test Accuracy: 46.65%\n",
            "Epoch 239/300, Loss: 0.0002025739998916496, Test Accuracy: 46.64%\n",
            "Epoch 240/300, Loss: 0.00020159844548122837, Test Accuracy: 46.66%\n",
            "Epoch 241/300, Loss: 0.00020061758182827717, Test Accuracy: 46.66%\n",
            "Epoch 242/300, Loss: 0.0001995534731808219, Test Accuracy: 46.65%\n",
            "Epoch 243/300, Loss: 0.00019851134852042198, Test Accuracy: 46.71%\n",
            "Epoch 244/300, Loss: 0.00019761933510982588, Test Accuracy: 46.65%\n",
            "Epoch 245/300, Loss: 0.0001966420889391742, Test Accuracy: 46.62%\n",
            "Epoch 246/300, Loss: 0.00019570992407121594, Test Accuracy: 46.68%\n",
            "Epoch 247/300, Loss: 0.00019470114085115868, Test Accuracy: 46.67%\n",
            "Epoch 248/300, Loss: 0.00019375438933609762, Test Accuracy: 46.63%\n",
            "Epoch 249/300, Loss: 0.0001927796494791398, Test Accuracy: 46.69%\n",
            "Epoch 250/300, Loss: 0.00019195915242885427, Test Accuracy: 46.69%\n",
            "Epoch 251/300, Loss: 0.0001910498728263606, Test Accuracy: 46.69%\n",
            "Epoch 252/300, Loss: 0.00019001223433149655, Test Accuracy: 46.68%\n",
            "Epoch 253/300, Loss: 0.0001890745614565565, Test Accuracy: 46.67%\n",
            "Epoch 254/300, Loss: 0.0001882319431349764, Test Accuracy: 46.63%\n",
            "Epoch 255/300, Loss: 0.00018735607255124936, Test Accuracy: 46.68%\n",
            "Epoch 256/300, Loss: 0.0001865948420255183, Test Accuracy: 46.68%\n",
            "Epoch 257/300, Loss: 0.00018558560840599523, Test Accuracy: 46.64%\n",
            "Epoch 258/300, Loss: 0.00018484312816501714, Test Accuracy: 46.69%\n",
            "Epoch 259/300, Loss: 0.00018392849760543424, Test Accuracy: 46.65%\n",
            "Epoch 260/300, Loss: 0.00018318141096406983, Test Accuracy: 46.62%\n",
            "Epoch 261/300, Loss: 0.00018227027613669335, Test Accuracy: 46.65%\n",
            "Epoch 262/300, Loss: 0.0001814353722806809, Test Accuracy: 46.65%\n",
            "Epoch 263/300, Loss: 0.00018066683781073475, Test Accuracy: 46.65%\n",
            "Epoch 264/300, Loss: 0.0001798346899459508, Test Accuracy: 46.68%\n",
            "Epoch 265/300, Loss: 0.00017899364958545854, Test Accuracy: 46.63%\n",
            "Epoch 266/300, Loss: 0.00017819192541356665, Test Accuracy: 46.68%\n",
            "Epoch 267/300, Loss: 0.00017731012721703226, Test Accuracy: 46.63%\n",
            "Epoch 268/300, Loss: 0.00017667133523285644, Test Accuracy: 46.66%\n",
            "Epoch 269/300, Loss: 0.0001757915030531378, Test Accuracy: 46.64%\n",
            "Epoch 270/300, Loss: 0.0001750488431011273, Test Accuracy: 46.68%\n",
            "Epoch 271/300, Loss: 0.0001743408538668815, Test Accuracy: 46.67%\n",
            "Epoch 272/300, Loss: 0.00017354170397115512, Test Accuracy: 46.59%\n",
            "Epoch 273/300, Loss: 0.00017284265196602434, Test Accuracy: 46.64%\n",
            "Epoch 274/300, Loss: 0.00017201550260498424, Test Accuracy: 46.64%\n",
            "Epoch 275/300, Loss: 0.00017126832519802704, Test Accuracy: 46.71%\n",
            "Epoch 276/300, Loss: 0.00017052674563727488, Test Accuracy: 46.63%\n",
            "Epoch 277/300, Loss: 0.00016982527441580594, Test Accuracy: 46.64%\n",
            "Epoch 278/300, Loss: 0.00016911440935814934, Test Accuracy: 46.71%\n",
            "Epoch 279/300, Loss: 0.0001683422199903507, Test Accuracy: 46.68%\n",
            "Epoch 280/300, Loss: 0.00016761780269121482, Test Accuracy: 46.65%\n",
            "Epoch 281/300, Loss: 0.00016690424898799756, Test Accuracy: 46.70%\n",
            "Epoch 282/300, Loss: 0.00016624875674689347, Test Accuracy: 46.66%\n",
            "Epoch 283/300, Loss: 0.00016556321627884447, Test Accuracy: 46.61%\n",
            "Epoch 284/300, Loss: 0.0001647875386177263, Test Accuracy: 46.67%\n",
            "Epoch 285/300, Loss: 0.00016419674004401275, Test Accuracy: 46.60%\n",
            "Epoch 286/300, Loss: 0.00016347833566048993, Test Accuracy: 46.69%\n",
            "Epoch 287/300, Loss: 0.00016278236912224475, Test Accuracy: 46.62%\n",
            "Epoch 288/300, Loss: 0.0001621998460239478, Test Accuracy: 46.70%\n",
            "Epoch 289/300, Loss: 0.0001615280467697782, Test Accuracy: 46.64%\n",
            "Epoch 290/300, Loss: 0.00016083611021826765, Test Accuracy: 46.70%\n",
            "Epoch 291/300, Loss: 0.0001602133931147822, Test Accuracy: 46.63%\n",
            "Epoch 292/300, Loss: 0.00015953709992567604, Test Accuracy: 46.68%\n",
            "Epoch 293/300, Loss: 0.00015893217100934926, Test Accuracy: 46.67%\n",
            "Epoch 294/300, Loss: 0.0001582775213921017, Test Accuracy: 46.69%\n",
            "Epoch 295/300, Loss: 0.0001576183837402863, Test Accuracy: 46.62%\n",
            "Epoch 296/300, Loss: 0.00015696090280027853, Test Accuracy: 46.68%\n",
            "Epoch 297/300, Loss: 0.00015640097819090692, Test Accuracy: 46.65%\n",
            "Epoch 298/300, Loss: 0.0001558025492278064, Test Accuracy: 46.61%\n",
            "Epoch 299/300, Loss: 0.00015520116060485325, Test Accuracy: 46.64%\n",
            "Epoch 300/300, Loss: 0.0001545431953062557, Test Accuracy: 46.67%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.54      0.52      1000\n",
            "           1       0.59      0.55      0.57      1000\n",
            "           2       0.35      0.37      0.36      1000\n",
            "           3       0.30      0.31      0.31      1000\n",
            "           4       0.40      0.41      0.41      1000\n",
            "           5       0.38      0.37      0.37      1000\n",
            "           6       0.50      0.52      0.51      1000\n",
            "           7       0.54      0.48      0.51      1000\n",
            "           8       0.58      0.61      0.59      1000\n",
            "           9       0.53      0.51      0.52      1000\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.47      0.47      0.47     10000\n",
            "weighted avg       0.47      0.47      0.47     10000\n",
            "\n",
            "time: 45min 46s (started: 2024-05-04 02:26:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_model(model2, train_loader, test_loader, num_epochs=300, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vKJXg9BYOtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ca7124-5ee4-4319-8d89-af502e010cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters  1738890 \n",
            "\n",
            "time: 923 µs (started: 2024-05-04 03:12:31 +00:00)\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model2.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable parameters \", total_params,  '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKoymvifSfNN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}